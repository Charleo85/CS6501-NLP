# Schedule

**Subject to change**

| | Date | Topics | Readings |
| ------------- |:-------------|:-----|:---- |
| 1 | Aug. 22 |Introduction to NLP | |
| 2 | Aug. 27 | Text classification, bag-of-words representations | |
| 3 | Aug. 29 | Logistic regression, discriminative models | |
| 4 | Sept. 3 | Naive Bayes classifier, generative models | |
| 5 | Sept. 5 | Statistical Language Modeling, $n$-gram models | |
| 6 | Sept. 10 | Sequence labeling (I) Part-of-speech tagging, HMMs | |
| 7 | Sept. 12 | Sequence labeling (II): Inference, Viterbi decoding | |
| 8 | Sept. 17 | Sequence labeling (III): learning HMMs  | |
| 9 | Sept. 19 | Parsing (I): (probabilistic) context-free grammar | |
| 10 | Sept. 24 | Parsing (II): phrase structure parsing and CKY algorithm | |
| 11 | Sept. 26 | Parsing (III): dependency grammar and transition based parsing | |
| 12 | Oct. 1 | *Reading day* | |
| 13 | Oct. 3 | *Reading day* | |
| 14 | Oct. 8 | Project proposal | |
| 15 | Oct. 10 | Statistical machine translation | |
| 16 | Oct. 15 | Discourse processing | |
| 17 | Oct. 17 | Feed-forward neural networks and back-propagation algorithm | |
| 18 | Oct. 22 | Representation learning (I): distributional representations  | |
| 19 | Oct. 24 | Representation learning (II): word embeddings | |
| 20 | Oct. 29 | Neural language modeling (I): text evaluation | |
| 21 | Oct. 31 | Neural language modeling (II): text generation | |
| 22 | Nov. 5 | Sequence-to-sequence models and attention mechanism | |
| 23 | Nov. 7 | Neural machine translation | |
| 24 | Nov. 12 | Convolutional neural networks for NLP (I) | |
| 25 | Nov. 14 | Convolutional neural networks for NLP (II) | |
| 26 | Nov. 19 | Generative adversarial networks and text generation | |
| 27 | Nov. 21 | Question answering | |
| 28 | Nov. 26 | *Thanksgiving* | |
| 29 | Nov. 28 | Project presentation | |
| 30 | Dec. 3 | Project presentation | |
| 31 | Dec. 5 | Project presentation | |
